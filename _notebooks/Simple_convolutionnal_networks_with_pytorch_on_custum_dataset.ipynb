{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait la mm chose qu'avant\n",
    "# Mais cette fois on le fait sur notre propre jeu de données\n",
    "# On a vu les principales astuces sur les tutos precedents\n",
    "# Celui ci sera sur la lecture des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok on commence avec la classe dataset, necessaire pour un NN en pytorch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models,transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torch\n",
    "import shutil\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cross/Fab2Alex.github.io/_notebooks'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast and GPUrious\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Fast and GPUrious\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"oulà mon gars tu vas prendre des années à m'apprendre un truc toi\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_de_donnee = \"/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce fichier existe deja\n"
     ]
    }
   ],
   "source": [
    "# on split notre set en train et val \n",
    "# Source path  \n",
    "source = '/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/train/'\n",
    "  \n",
    "if os.path.exists('/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val'):\n",
    "    print(\"Ce fichier existe deja\")\n",
    "else:    \n",
    "    os.mkdir('/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val')    \n",
    "    \n",
    "# Destination path  \n",
    "destination = '/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/'\n",
    "  \n",
    "# Move the content of  \n",
    "# source to destination  \n",
    "#dest = shutil.move(source, destination)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = '/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/dogs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer les fichiers en listes\n",
    "cats = os.listdir(source+\"cats\")\n",
    "dogs = os.listdir(source+\"dogs\")\n",
    "panda = os.listdir(source+\"panda\")\n",
    "# on choisit de maniere random 20 % des fichiers que l on va couper coller ds val/cats, val/dogs, val/panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "panda_val = []\n",
    "while len(panda_val)<200:\n",
    "    choix_aleatoire = random.choice(panda)\n",
    "    if choix_aleatoire in panda_val:\n",
    "        choix_aleatoire = random.choice(panda)\n",
    "    else:    \n",
    "        panda_val.append(choix_aleatoire)\n",
    "    \n",
    "\n",
    "#cats_val = [random.choice(i) for i,j in enumerate(cats) if i<=len(cats)*0.2]\n",
    "len(panda_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_val = []\n",
    "while len(cats_val)<200:\n",
    "    choix_aleatoire = random.choice(cats)\n",
    "    if choix_aleatoire in cats_val:\n",
    "        choix_aleatoire = random.choice(cats)\n",
    "    else:    \n",
    "        cats_val.append(choix_aleatoire)\n",
    "    \n",
    "\n",
    "#cats_val = [random.choice(i) for i,j in enumerate(cats) if i<=len(cats)*0.2]\n",
    "len(cats_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs_val = []\n",
    "while len(dogs_val)<200:\n",
    "    choix_aleatoire = random.choice(dogs)\n",
    "    if choix_aleatoire in dogs_val:\n",
    "        choix_aleatoire = random.choice(dogs)\n",
    "    else:    \n",
    "        dogs_val.append(choix_aleatoire)\n",
    "    \n",
    "\n",
    "#cats_val = [random.choice(i) for i,j in enumerate(cats) if i<=len(cats)*0.2]\n",
    "len(dogs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats_00284.jpg',\n",
       " 'cats_00670.jpg',\n",
       " 'cats_00380.jpg',\n",
       " 'cats_00178.jpg',\n",
       " 'cats_00956.jpg',\n",
       " 'cats_00713.jpg',\n",
       " 'cats_00971.jpg',\n",
       " 'cats_00276.jpg',\n",
       " 'cats_00261.jpg',\n",
       " 'cats_00816.jpg',\n",
       " 'cats_00418.jpg',\n",
       " 'cats_00460.jpg',\n",
       " 'cats_00728.jpg',\n",
       " 'cats_00766.jpg',\n",
       " 'cats_01000.jpg',\n",
       " 'cats_00782.jpg',\n",
       " 'cats_00234.jpg',\n",
       " 'cats_00344.jpg',\n",
       " 'cats_00616.jpg',\n",
       " 'cats_00219.jpg',\n",
       " 'cats_00558.jpg',\n",
       " 'cats_00266.jpg',\n",
       " 'cats_00543.jpg',\n",
       " 'cats_00350.jpg',\n",
       " 'cats_00034.jpg',\n",
       " 'cats_00549.jpg',\n",
       " 'cats_00775.jpg',\n",
       " 'cats_00202.jpg',\n",
       " 'cats_00612.jpg',\n",
       " 'cats_00228.jpg',\n",
       " 'cats_00062.jpg',\n",
       " 'cats_00102.jpg',\n",
       " 'cats_00685.jpg',\n",
       " 'cats_00691.jpg',\n",
       " 'cats_00826.jpg',\n",
       " 'cats_00184.jpg',\n",
       " 'cats_00607.jpg',\n",
       " 'cats_00485.jpg',\n",
       " 'cats_00891.jpg',\n",
       " 'cats_00458.jpg',\n",
       " 'cats_00565.jpg',\n",
       " 'cats_00421.jpg',\n",
       " 'cats_00226.jpg',\n",
       " 'cats_00932.jpg',\n",
       " 'cats_00959.jpg',\n",
       " 'cats_00340.jpg',\n",
       " 'cats_00437.jpg',\n",
       " 'cats_00432.jpg',\n",
       " 'cats_00931.jpg',\n",
       " 'cats_00704.jpg',\n",
       " 'cats_00929.jpg',\n",
       " 'cats_00477.jpg',\n",
       " 'cats_00004.jpg',\n",
       " 'cats_00893.jpg',\n",
       " 'cats_00999.jpg',\n",
       " 'cats_00463.jpg',\n",
       " 'cats_00424.jpg',\n",
       " 'cats_00496.jpg',\n",
       " 'cats_00646.jpg',\n",
       " 'cats_00064.jpg',\n",
       " 'cats_00490.jpg',\n",
       " 'cats_00150.jpg',\n",
       " 'cats_00631.jpg',\n",
       " 'cats_00606.jpg',\n",
       " 'cats_00546.jpg',\n",
       " 'cats_00948.jpg',\n",
       " 'cats_00309.jpg',\n",
       " 'cats_00311.jpg',\n",
       " 'cats_00331.jpg',\n",
       " 'cats_00428.jpg',\n",
       " 'cats_00238.jpg',\n",
       " 'cats_00952.jpg',\n",
       " 'cats_00044.jpg',\n",
       " 'cats_00983.jpg',\n",
       " 'cats_00026.jpg',\n",
       " 'cats_00969.jpg',\n",
       " 'cats_00335.jpg',\n",
       " 'cats_00853.jpg',\n",
       " 'cats_00822.jpg',\n",
       " 'cats_00793.jpg',\n",
       " 'cats_00494.jpg',\n",
       " 'cats_00163.jpg',\n",
       " 'cats_00856.jpg',\n",
       " 'cats_00323.jpg',\n",
       " 'cats_00461.jpg',\n",
       " 'cats_00667.jpg',\n",
       " 'cats_00810.jpg',\n",
       " 'cats_00080.jpg',\n",
       " 'cats_00818.jpg',\n",
       " 'cats_00280.jpg',\n",
       " 'cats_00774.jpg',\n",
       " 'cats_00161.jpg',\n",
       " 'cats_00679.jpg',\n",
       " 'cats_00054.jpg',\n",
       " 'cats_00201.jpg',\n",
       " 'cats_00128.jpg',\n",
       " 'cats_00706.jpg',\n",
       " 'cats_00041.jpg',\n",
       " 'cats_00415.jpg',\n",
       " 'cats_00429.jpg',\n",
       " 'cats_00268.jpg',\n",
       " 'cats_00006.jpg',\n",
       " 'cats_00671.jpg',\n",
       " 'cats_00724.jpg',\n",
       " 'cats_00760.jpg',\n",
       " 'cats_00189.jpg',\n",
       " 'cats_00492.jpg',\n",
       " 'cats_00028.jpg',\n",
       " 'cats_00577.jpg',\n",
       " 'cats_00506.jpg',\n",
       " 'cats_00799.jpg',\n",
       " 'cats_00168.jpg',\n",
       " 'cats_00416.jpg',\n",
       " 'cats_00920.jpg',\n",
       " 'cats_00743.jpg',\n",
       " 'cats_00145.jpg',\n",
       " 'cats_00198.jpg',\n",
       " 'cats_00797.jpg',\n",
       " 'cats_00896.jpg',\n",
       " 'cats_00829.jpg',\n",
       " 'cats_00965.jpg',\n",
       " 'cats_00941.jpg',\n",
       " 'cats_00879.jpg',\n",
       " 'cats_00519.jpg',\n",
       " 'cats_00248.jpg',\n",
       " 'cats_00507.jpg',\n",
       " 'cats_00536.jpg',\n",
       " 'cats_00162.jpg',\n",
       " 'cats_00669.jpg',\n",
       " 'cats_00407.jpg',\n",
       " 'cats_00796.jpg',\n",
       " 'cats_00894.jpg',\n",
       " 'cats_00456.jpg',\n",
       " 'cats_00586.jpg',\n",
       " 'cats_00834.jpg',\n",
       " 'cats_00312.jpg',\n",
       " 'cats_00092.jpg',\n",
       " 'cats_00830.jpg',\n",
       " 'cats_00940.jpg',\n",
       " 'cats_00758.jpg',\n",
       " 'cats_00046.jpg',\n",
       " 'cats_00206.jpg',\n",
       " 'cats_00147.jpg',\n",
       " 'cats_00070.jpg',\n",
       " 'cats_00301.jpg',\n",
       " 'cats_00086.jpg',\n",
       " 'cats_00159.jpg',\n",
       " 'cats_00865.jpg',\n",
       " 'cats_00609.jpg',\n",
       " 'cats_00936.jpg',\n",
       " 'cats_00475.jpg',\n",
       " 'cats_00203.jpg',\n",
       " 'cats_00282.jpg',\n",
       " 'cats_00878.jpg',\n",
       " 'cats_00899.jpg',\n",
       " 'cats_00353.jpg',\n",
       " 'cats_00154.jpg',\n",
       " 'cats_00213.jpg',\n",
       " 'cats_00967.jpg',\n",
       " 'cats_00805.jpg',\n",
       " 'cats_00091.jpg',\n",
       " 'cats_00638.jpg',\n",
       " 'cats_00441.jpg',\n",
       " 'cats_00723.jpg',\n",
       " 'cats_00374.jpg',\n",
       " 'cats_00689.jpg',\n",
       " 'cats_00420.jpg',\n",
       " 'cats_00651.jpg',\n",
       " 'cats_00385.jpg',\n",
       " 'cats_00910.jpg',\n",
       " 'cats_00827.jpg',\n",
       " 'cats_00582.jpg',\n",
       " 'cats_00789.jpg',\n",
       " 'cats_00851.jpg',\n",
       " 'cats_00762.jpg',\n",
       " 'cats_00552.jpg',\n",
       " 'cats_00603.jpg',\n",
       " 'cats_00980.jpg',\n",
       " 'cats_00947.jpg',\n",
       " 'cats_00049.jpg',\n",
       " 'cats_00767.jpg',\n",
       " 'cats_00526.jpg',\n",
       " 'cats_00394.jpg',\n",
       " 'cats_00396.jpg',\n",
       " 'cats_00579.jpg',\n",
       " 'cats_00125.jpg',\n",
       " 'cats_00785.jpg',\n",
       " 'cats_00913.jpg',\n",
       " 'cats_00887.jpg',\n",
       " 'cats_00598.jpg',\n",
       " 'cats_00141.jpg',\n",
       " 'cats_00702.jpg',\n",
       " 'cats_00346.jpg',\n",
       " 'cats_00998.jpg',\n",
       " 'cats_00440.jpg',\n",
       " 'cats_00025.jpg',\n",
       " 'cats_00544.jpg',\n",
       " 'cats_00875.jpg',\n",
       " 'cats_00898.jpg',\n",
       " 'cats_00288.jpg']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifier que l on a pas deux fois la mm image ds cette liste\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "\n",
    "for i in cats_val:\n",
    "    cnt[i] += 1  \n",
    "    \n",
    "# printer les items qui ne sont pas unique\n",
    "for i,j in cnt.items():\n",
    "    if j > 1 :\n",
    "        print (i) \n",
    "    else:\n",
    "        continue\n",
    "#cats_val.remove(\"cats_00288.jpg\")    \n",
    "#cats_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifier que l on a pas deux fois la mm image ds cette liste\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "\n",
    "for i in panda_val:\n",
    "    cnt[i] += 1  \n",
    "    \n",
    "# printer les items qui ne sont pas unique\n",
    "for i,j in cnt.items():\n",
    "    if j > 1 :\n",
    "        print (i) \n",
    "    else:\n",
    "        continue\n",
    "#cats_val.remove(\"cats_00288.jpg\")    \n",
    "#cats_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifier que l on a pas deux fois la mm image ds cette liste\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "\n",
    "for i in dogs_val:\n",
    "    cnt[i] += 1  \n",
    "    \n",
    "# printer les items qui ne sont pas unique\n",
    "for i,j in cnt.items():\n",
    "    if j > 1 :\n",
    "        print (i) \n",
    "    else:\n",
    "        continue\n",
    "#cats_val.remove(\"cats_00288.jpg\")    \n",
    "#cats_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintenant on bouge le jdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on split notre set en train et val \n",
    "# Source path  \n",
    "source = '/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/'\n",
    "  \n",
    "if os.path.exists('/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val'):\n",
    "    print(\"Ce fichier existe deja\")\n",
    "else:    \n",
    "    os.mkdir('/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val')    \n",
    "    \n",
    "# Destination path  \n",
    "destination = '/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val'\n",
    "  \n",
    "# Move the content of  \n",
    "# source to destination  \n",
    "dest = shutil.move(source, destination)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce fichier existe deja\n"
     ]
    }
   ],
   "source": [
    "source = '/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/train/cats'\n",
    "  \n",
    "if os.path.exists('/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/cats'):\n",
    "    print(\"Ce fichier existe deja\")\n",
    "else:    \n",
    "    os.mkdir('/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/cats')    \n",
    "    \n",
    "# Destination path  \n",
    "destination = '/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/cats/'\n",
    "  \n",
    "# Move the content of  \n",
    "# source to destination  \n",
    "for i in cats_val:\n",
    "    dest = shutil.move(source+\"/\"+i, destination)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce fichier existe deja\n"
     ]
    }
   ],
   "source": [
    "source = '/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/train/panda'\n",
    "  \n",
    "if os.path.exists('/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/panda'):\n",
    "    print(\"Ce fichier existe deja\")\n",
    "else:    \n",
    "    os.mkdir('/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/panda')    \n",
    "    \n",
    "# Destination path  \n",
    "destination = '/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/panda/'\n",
    "  \n",
    "# Move the content of  \n",
    "# source to destination  \n",
    "for i in panda_val:\n",
    "    dest = shutil.move(source+\"/\"+i, destination)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce fichier existe deja\n"
     ]
    }
   ],
   "source": [
    "source = '/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/train/dogs'\n",
    "  \n",
    "if os.path.exists('/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/dogs'):\n",
    "    print(\"Ce fichier existe deja\")\n",
    "else:    \n",
    "    os.mkdir('/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/dogs')    \n",
    "    \n",
    "# Destination path  \n",
    "destination = '/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/dogs/'\n",
    "  \n",
    "# Move the content of  \n",
    "# source to destination  \n",
    "for i in dogs_val:\n",
    "    dest = shutil.move(source+\"/\"+i, destination)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch et et dataloader sont parmis les choses les plus importants à maitriser pour Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def __len__(self):\n",
    "        raise NotImplementedError    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculer la moyenne des couleurs des images pour la normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "train = \"/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/train/\"\n",
    "val = \"/mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/val/\"\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=train,transform=transforms)\n",
    "val_data = torchvision.datasets.ImageFolder(root=val,transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 2400\n",
       "    Root location: /mnt/fa325e08-4cfa-41a4-b31c-25293484c517/sauvegarde3/cross/Bureau/Alex/Tout/Datasets/animals/train/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=64, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "val_data_loader  = torch.utils.data.DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=12288, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # on a ce que l'on appelle ici une FC, une fully connected, autrement dit un perceptron\n",
    "        # cette couche necessite en entree les dimensions exactes de l'input\n",
    "        # le 64 correpond à l'output\n",
    "        self.fc1 = nn.Linear(3*64*64, 64)\n",
    "        # l'output de la fc1 est mis en input de la FC2\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        # mm logique que precedemment\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        # puis on precise une sortie de 10 (correspondant au nombres de classes disponibles)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # F.relu correspond simplement aux fonctions d'activations\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (act1): Tanh()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (act2): Tanh()\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=384, out_features=32, bias=True)\n",
      "  (act3): Tanh()\n",
      "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Print(nn.Module):\n",
    "    def forward(self, x):\n",
    "        #print((x.size())\n",
    "        return x.view(x.size(0),-1)\n",
    "a = Print()  \n",
    "\n",
    "# On reprend un reseau de neurones simple mais en y ajoutant des convolutions\n",
    "class Brain(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # ds cet ordre pr la Conv2D -> channel, filtres (nombre d outputs features) \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        # 6 represente le nbre de feature en output\n",
    "        self.conv2 = nn.Conv2d(64, 6, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(384, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        \n",
    "        # D'où vient ce 8*8*6\n",
    "        # En keras ou tensorflow il exist la methode flatten\n",
    "        # Mais comment faire en pytorch?\n",
    "        # source: http://cs231n.github.io/convolutional-networks/#pool\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=maxpool2#torch.nn.Conv2d\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=maxpool2#torch.nn.MaxPool2d\n",
    "        \n",
    "        out = a.forward(out)\n",
    "        print(out.shape)\n",
    "        print(out.shape[1])\n",
    "        \n",
    "        #out = out.view(-1, 8*8*6)\n",
    "        #a.forward(out)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = Brain()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 85 and 87 in dimension 3 at /pytorch/aten/src/TH/generic/THTensor.cpp:689",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-446482c818c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/fastai/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/fastai/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/fastai/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/fastai/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 85 and 87 in dimension 3 at /pytorch/aten/src/TH/generic/THTensor.cpp:689"
     ]
    }
   ],
   "source": [
    "for loader in [train_data_loader, val_data_loader]:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "    \n",
    "    print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
