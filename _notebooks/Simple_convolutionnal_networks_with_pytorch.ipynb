{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe les pacakges necessaire\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch\n",
    "import time\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# telechargement des données\n",
    "# Où les données seront stockées\n",
    "\n",
    "data_path = '/home/cross/Fab2Alex.github.io/Simple_CNN_en_pytorch/'\n",
    "\n",
    "# Training set\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "# Val set\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement les données\n",
    "# et transformations des données (en tenseur et normalisées)\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                   (0.2470, 0.2435, 0.2616))\n",
    "                          ]))\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                   (0.2470, 0.2435, 0.2616))\n",
    "                          ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on prends les données et on les stockent ds une variable en precisant le Batch size\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle = False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-1.0531e+00, -1.3072e+00, -1.1960e+00,  ...,  5.1866e-01,\n",
      "            4.2339e-01,  3.5989e-01],\n",
      "          [-1.7358e+00, -1.9899e+00, -1.7041e+00,  ..., -3.7033e-02,\n",
      "           -1.0054e-01, -5.2909e-02],\n",
      "          [-1.5930e+00, -1.7358e+00, -1.2119e+00,  ..., -1.1642e-01,\n",
      "           -8.4663e-02, -2.5931e-01],\n",
      "          ...,\n",
      "          [ 1.3125e+00,  1.2014e+00,  1.1537e+00,  ...,  5.5041e-01,\n",
      "           -1.1008e+00, -1.1484e+00],\n",
      "          [ 8.6794e-01,  7.5681e-01,  9.6321e-01,  ...,  9.3145e-01,\n",
      "           -4.4983e-01, -6.7210e-01],\n",
      "          [ 8.2031e-01,  6.7742e-01,  8.5207e-01,  ...,  1.4395e+00,\n",
      "            4.0752e-01, -3.7033e-02]],\n",
      "\n",
      "         [[-9.8219e-01, -1.2399e+00, -1.2077e+00,  ...,  1.4516e-01,\n",
      "            3.2427e-02,  1.6322e-02],\n",
      "          [-1.6586e+00, -1.9807e+00, -1.8519e+00,  ..., -5.6346e-01,\n",
      "           -6.4398e-01, -5.7956e-01],\n",
      "          [-1.5942e+00, -1.8680e+00, -1.5459e+00,  ..., -6.2788e-01,\n",
      "           -6.2788e-01, -8.0503e-01],\n",
      "          ...,\n",
      "          [ 7.5715e-01,  4.8337e-01,  6.1221e-01,  ...,  1.6127e-01,\n",
      "           -1.4814e+00, -1.4331e+00],\n",
      "          [ 2.5790e-01,  2.1737e-04,  3.3842e-01,  ...,  4.0284e-01,\n",
      "           -9.8219e-01, -1.1271e+00],\n",
      "          [ 3.3842e-01,  9.6848e-02,  3.0621e-01,  ...,  9.8262e-01,\n",
      "           -8.0308e-02, -4.9904e-01]],\n",
      "\n",
      "         [[-7.6354e-01, -1.0334e+00, -1.0634e+00,  ..., -8.8955e-02,\n",
      "           -1.7890e-01, -1.6391e-01],\n",
      "          [-1.4081e+00, -1.7080e+00, -1.7080e+00,  ..., -8.8346e-01,\n",
      "           -9.5842e-01, -8.5348e-01],\n",
      "          [-1.3931e+00, -1.7080e+00, -1.5880e+00,  ..., -9.5842e-01,\n",
      "           -9.5842e-01, -1.0783e+00],\n",
      "          ...,\n",
      "          [-2.6884e-01, -1.1983e+00, -1.3182e+00,  ..., -6.5860e-01,\n",
      "           -1.6030e+00, -1.4081e+00],\n",
      "          [-2.6884e-01, -1.0783e+00, -1.2582e+00,  ..., -2.9882e-01,\n",
      "           -1.1983e+00, -1.1983e+00],\n",
      "          [ 3.0971e-02, -2.9882e-01, -4.0376e-01,  ...,  3.9075e-01,\n",
      "           -4.4873e-01, -6.2862e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5515e-01,  1.0598e-02, -3.2281e-01,  ..., -5.4509e-01,\n",
      "           -6.0860e-01, -7.3561e-01],\n",
      "          [ 2.3287e-01,  3.1226e-01, -5.2790e-03,  ..., -4.6571e-01,\n",
      "           -7.6737e-01, -8.6263e-01],\n",
      "          [ 2.3287e-01,  2.1700e-01, -1.6405e-01,  ..., -7.3561e-01,\n",
      "           -9.1026e-01, -9.2613e-01],\n",
      "          ...,\n",
      "          [ 7.8856e-01,  4.8690e-01,  4.5515e-01,  ..., -1.3231e+00,\n",
      "           -1.0214e+00, -5.1334e-01],\n",
      "          [ 6.2979e-01,  4.8690e-01,  5.3453e-01,  ..., -3.5457e-01,\n",
      "           -3.7033e-02,  8.9982e-02],\n",
      "          [ 5.9804e-01,  5.1866e-01,  5.9804e-01,  ...,  2.8050e-01,\n",
      "            2.8050e-01,  2.8050e-01]],\n",
      "\n",
      "         [[ 8.6989e-01,  2.2569e-01, -3.0578e-01,  ..., -4.5072e-01,\n",
      "           -5.3125e-01, -6.7619e-01],\n",
      "          [ 5.9610e-01,  4.8337e-01,  3.2427e-02,  ..., -3.8630e-01,\n",
      "           -6.9230e-01, -8.0503e-01],\n",
      "          [ 5.1558e-01,  3.7063e-01, -1.2862e-01,  ..., -6.6009e-01,\n",
      "           -8.5335e-01, -8.6945e-01],\n",
      "          ...,\n",
      "          [ 7.0884e-01,  4.9947e-01,  5.9610e-01,  ..., -1.4331e+00,\n",
      "           -1.1271e+00, -6.4398e-01],\n",
      "          [ 4.9947e-01,  4.6726e-01,  6.1221e-01,  ..., -4.8293e-01,\n",
      "           -1.4473e-01, -3.1993e-02],\n",
      "          [ 4.0284e-01,  4.0284e-01,  5.3168e-01,  ...,  1.6127e-01,\n",
      "            1.7737e-01,  1.6127e-01]],\n",
      "\n",
      "         [[ 1.0953e+00,  3.3079e-01, -2.8383e-01,  ..., -6.4361e-01,\n",
      "           -6.4361e-01, -6.5860e-01],\n",
      "          [ 8.2548e-01,  6.0062e-01,  6.0952e-02,  ..., -5.3868e-01,\n",
      "           -7.7853e-01, -7.9352e-01],\n",
      "          [ 7.5052e-01,  5.2566e-01, -2.8992e-02,  ..., -7.4855e-01,\n",
      "           -8.8346e-01, -8.8346e-01],\n",
      "          ...,\n",
      "          [ 7.8051e-01,  6.9056e-01,  8.4047e-01,  ..., -1.1683e+00,\n",
      "           -8.5348e-01, -3.4380e-01],\n",
      "          [ 2.1086e-01,  2.4084e-01,  4.2073e-01,  ..., -2.6884e-01,\n",
      "            9.0934e-02,  2.5583e-01],\n",
      "          [ 9.0934e-02,  1.2092e-01,  2.8581e-01,  ...,  3.7576e-01,\n",
      "            4.2073e-01,  4.5071e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0587e+00,  2.0270e+00,  2.0270e+00,  ...,  2.0270e+00,\n",
      "            2.0270e+00,  2.0270e+00],\n",
      "          [ 2.0587e+00,  2.0587e+00,  2.0587e+00,  ...,  2.0587e+00,\n",
      "            2.0587e+00,  2.0587e+00],\n",
      "          [ 2.0587e+00,  2.0428e+00,  2.0428e+00,  ...,  2.0428e+00,\n",
      "            2.0428e+00,  2.0428e+00],\n",
      "          ...,\n",
      "          [-1.9580e-01, -2.2755e-01, -3.2281e-01,  ..., -8.4675e-01,\n",
      "           -8.4675e-01, -8.4675e-01],\n",
      "          [-2.2755e-01, -3.3869e-01, -4.1808e-01,  ..., -9.1026e-01,\n",
      "           -8.7850e-01, -7.5149e-01],\n",
      "          [-3.0694e-01, -4.1808e-01, -4.8158e-01,  ..., -7.5149e-01,\n",
      "           -7.3561e-01, -7.1973e-01]],\n",
      "\n",
      "         [[ 2.1261e+00,  2.0939e+00,  2.0939e+00,  ...,  2.0939e+00,\n",
      "            2.0939e+00,  2.0939e+00],\n",
      "          [ 2.1261e+00,  2.1261e+00,  2.1261e+00,  ...,  2.1261e+00,\n",
      "            2.1261e+00,  2.1261e+00],\n",
      "          [ 2.1261e+00,  2.1100e+00,  2.1100e+00,  ...,  2.1100e+00,\n",
      "            2.1100e+00,  2.1100e+00],\n",
      "          ...,\n",
      "          [-4.8098e-02, -8.0308e-02, -1.7694e-01,  ..., -6.7619e-01,\n",
      "           -6.9230e-01, -6.9230e-01],\n",
      "          [-8.0308e-02, -1.9304e-01, -2.7357e-01,  ..., -7.7282e-01,\n",
      "           -7.5672e-01, -6.2788e-01],\n",
      "          [-1.6083e-01, -2.7357e-01, -3.3799e-01,  ..., -6.1177e-01,\n",
      "           -6.1177e-01, -5.9567e-01]],\n",
      "\n",
      "         [[ 2.1147e+00,  2.0847e+00,  2.0847e+00,  ...,  2.0847e+00,\n",
      "            2.0847e+00,  2.0847e+00],\n",
      "          [ 2.1147e+00,  2.1147e+00,  2.1147e+00,  ...,  2.1147e+00,\n",
      "            2.1147e+00,  2.1147e+00],\n",
      "          [ 2.1147e+00,  2.0997e+00,  2.0997e+00,  ...,  2.0997e+00,\n",
      "            2.0997e+00,  2.0997e+00],\n",
      "          ...,\n",
      "          [-2.8992e-02, -4.3983e-02, -1.1894e-01,  ..., -5.0869e-01,\n",
      "           -5.2369e-01, -5.2369e-01],\n",
      "          [-5.8973e-02, -1.4892e-01, -2.3886e-01,  ..., -6.1363e-01,\n",
      "           -5.8365e-01, -4.7871e-01],\n",
      "          [-1.3393e-01, -2.3886e-01, -2.9882e-01,  ..., -4.6372e-01,\n",
      "           -4.6372e-01, -4.4873e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.7992e-01, -1.3229e-01, -8.4663e-02,  ...,  6.2979e-01,\n",
      "           -5.2790e-03, -3.5457e-01],\n",
      "          [-2.2755e-01, -1.4817e-01, -6.8786e-02,  ...,  5.8216e-01,\n",
      "            2.6475e-02, -3.5457e-01],\n",
      "          [-1.7992e-01, -6.8786e-02,  4.2352e-02,  ...,  6.6155e-01,\n",
      "            1.0586e-01, -3.0694e-01],\n",
      "          ...,\n",
      "          [ 6.2979e-01,  7.0918e-01,  7.8856e-01,  ...,  9.4733e-01,\n",
      "            1.2966e+00,  1.2014e+00],\n",
      "          [ 7.8856e-01,  7.8856e-01,  8.6794e-01,  ...,  9.7908e-01,\n",
      "            1.1855e+00,  1.0743e+00],\n",
      "          [ 7.5681e-01,  7.2505e-01,  8.2031e-01,  ...,  1.2649e+00,\n",
      "            1.3442e+00,  1.2172e+00]],\n",
      "\n",
      "         [[-6.4203e-02, -1.5888e-02,  4.8532e-02,  ...,  6.9273e-01,\n",
      "            4.8532e-02, -3.2188e-01],\n",
      "          [-1.1252e-01, -3.1993e-02,  4.8532e-02,  ...,  6.4442e-01,\n",
      "            8.0743e-02, -3.2188e-01],\n",
      "          [-6.4203e-02,  3.2427e-02,  1.4516e-01,  ...,  7.2494e-01,\n",
      "            1.6127e-01, -2.4136e-01],\n",
      "          ...,\n",
      "          [ 6.9273e-01,  7.7326e-01,  8.5378e-01,  ...,  9.0210e-01,\n",
      "            1.2242e+00,  1.1276e+00],\n",
      "          [ 8.5378e-01,  8.5378e-01,  9.3431e-01,  ...,  9.5041e-01,\n",
      "            1.1437e+00,  1.0148e+00],\n",
      "          [ 8.2157e-01,  7.8936e-01,  8.8599e-01,  ...,  1.2403e+00,\n",
      "            1.3047e+00,  1.1598e+00]],\n",
      "\n",
      "         [[ 1.6589e-01,  1.8088e-01,  2.2585e-01,  ...,  6.9056e-01,\n",
      "            1.0592e-01, -5.8973e-02],\n",
      "          [ 1.2092e-01,  1.9587e-01,  2.8581e-01,  ...,  6.4559e-01,\n",
      "            1.3591e-01, -7.3964e-02],\n",
      "          [ 1.6589e-01,  3.3079e-01,  4.2073e-01,  ...,  7.2054e-01,\n",
      "            1.8088e-01, -1.7890e-01],\n",
      "          ...,\n",
      "          [ 7.0555e-01,  7.9550e-01,  8.5546e-01,  ...,  8.1049e-01,\n",
      "            1.2002e+00,  1.0653e+00],\n",
      "          [ 8.5546e-01,  8.5546e-01,  9.3041e-01,  ...,  7.2054e-01,\n",
      "            1.0054e+00,  9.6039e-01],\n",
      "          [ 8.2548e-01,  7.9550e-01,  8.8544e-01,  ...,  1.0204e+00,\n",
      "            1.1703e+00,  1.0953e+00]]],\n",
      "\n",
      "\n",
      "        [[[-7.8324e-01, -8.3087e-01, -8.9438e-01,  ..., -7.9912e-01,\n",
      "           -8.4675e-01, -8.7850e-01],\n",
      "          [-7.8324e-01, -8.6263e-01, -9.4201e-01,  ..., -7.3561e-01,\n",
      "           -7.8324e-01, -7.9912e-01],\n",
      "          [-8.6263e-01, -9.5789e-01, -1.0055e+00,  ..., -7.1973e-01,\n",
      "           -7.6737e-01, -7.8324e-01],\n",
      "          ...,\n",
      "          [-1.8152e+00, -1.8470e+00, -1.8946e+00,  ..., -1.4977e+00,\n",
      "           -1.4818e+00, -1.5295e+00],\n",
      "          [-1.9899e+00, -1.9899e+00, -1.9899e+00,  ..., -1.7994e+00,\n",
      "           -1.7994e+00, -1.7835e+00],\n",
      "          [-6.0860e-01, -6.7210e-01, -7.0386e-01,  ..., -4.1808e-01,\n",
      "           -4.1808e-01, -3.7045e-01]],\n",
      "\n",
      "         [[-8.0308e-02, -8.0308e-02, -1.1252e-01,  ...,  1.9348e-01,\n",
      "            1.7737e-01,  1.9348e-01],\n",
      "          [-1.5888e-02, -6.4203e-02, -9.6413e-02,  ...,  2.0958e-01,\n",
      "            1.9348e-01,  2.2569e-01],\n",
      "          [-4.8098e-02, -9.6413e-02, -1.1252e-01,  ...,  1.6127e-01,\n",
      "            1.4516e-01,  1.9348e-01],\n",
      "          ...,\n",
      "          [-1.4009e+00, -1.4653e+00, -1.4653e+00,  ..., -9.9829e-01,\n",
      "           -9.8219e-01, -1.0305e+00],\n",
      "          [-1.6747e+00, -1.7713e+00, -1.8680e+00,  ..., -1.3687e+00,\n",
      "           -1.3848e+00, -1.3687e+00],\n",
      "          [-3.7020e-01, -4.9904e-01, -5.9567e-01,  ..., -1.1252e-01,\n",
      "           -1.2862e-01, -6.4203e-02]],\n",
      "\n",
      "         [[ 7.9550e-01,  7.5052e-01,  7.2054e-01,  ...,  9.9038e-01,\n",
      "            9.6039e-01,  9.7539e-01],\n",
      "          [ 8.4047e-01,  7.8051e-01,  7.3553e-01,  ...,  9.6039e-01,\n",
      "            9.4540e-01,  9.7539e-01],\n",
      "          [ 8.4047e-01,  7.6552e-01,  7.5052e-01,  ...,  8.8544e-01,\n",
      "            8.7045e-01,  9.0043e-01],\n",
      "          ...,\n",
      "          [-7.1856e-01, -7.9352e-01, -7.9352e-01,  ..., -5.2369e-01,\n",
      "           -5.0869e-01, -5.5367e-01],\n",
      "          [-1.0184e+00, -1.1083e+00, -1.1683e+00,  ..., -8.8346e-01,\n",
      "           -8.8346e-01, -8.6847e-01],\n",
      "          [ 1.5980e-02, -8.8955e-02, -1.6391e-01,  ...,  1.9587e-01,\n",
      "            1.9587e-01,  2.4084e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.5789e-01, -8.7850e-01, -7.8324e-01,  ..., -1.4659e+00,\n",
      "           -1.0531e+00, -1.0055e+00],\n",
      "          [-8.6263e-01, -7.5149e-01, -6.0860e-01,  ..., -1.6247e+00,\n",
      "           -9.5789e-01, -8.1500e-01],\n",
      "          [-8.9438e-01, -7.6737e-01, -6.8798e-01,  ..., -1.6882e+00,\n",
      "           -9.2613e-01, -6.7210e-01],\n",
      "          ...,\n",
      "          [-1.7676e+00, -1.7676e+00, -1.7676e+00,  ..., -1.1325e+00,\n",
      "           -1.1325e+00, -1.1643e+00],\n",
      "          [-1.7676e+00, -1.7676e+00, -1.7676e+00,  ..., -1.1484e+00,\n",
      "           -1.2754e+00, -1.3866e+00],\n",
      "          [-1.7676e+00, -1.7676e+00, -1.7676e+00,  ..., -1.2119e+00,\n",
      "           -1.4977e+00, -1.6565e+00]],\n",
      "\n",
      "         [[-1.4473e-01, -3.1993e-02,  9.6848e-02,  ..., -1.2238e+00,\n",
      "           -9.8219e-01, -9.1777e-01],\n",
      "          [-4.8098e-02,  9.6848e-02,  2.7400e-01,  ..., -1.4975e+00,\n",
      "           -9.8219e-01, -8.2114e-01],\n",
      "          [-8.0308e-02,  9.6848e-02,  2.2569e-01,  ..., -1.6586e+00,\n",
      "           -1.0627e+00, -8.0503e-01],\n",
      "          ...,\n",
      "          [-1.7552e+00, -1.7552e+00, -1.7552e+00,  ..., -7.5672e-01,\n",
      "           -6.9230e-01, -6.7619e-01],\n",
      "          [-1.7552e+00, -1.7552e+00, -1.7552e+00,  ..., -7.5672e-01,\n",
      "           -8.6945e-01, -9.6608e-01],\n",
      "          [-1.7552e+00, -1.7552e+00, -1.7552e+00,  ..., -8.2114e-01,\n",
      "           -1.1593e+00, -1.3526e+00]],\n",
      "\n",
      "         [[-8.9845e-01, -7.7853e-01, -6.4361e-01,  ..., -1.0783e+00,\n",
      "           -9.1344e-01, -8.6847e-01],\n",
      "          [-8.5348e-01, -7.3356e-01, -5.8365e-01,  ..., -1.3482e+00,\n",
      "           -9.4343e-01, -8.5348e-01],\n",
      "          [-9.1344e-01, -8.0851e-01, -7.6354e-01,  ..., -1.5131e+00,\n",
      "           -9.7341e-01, -7.1856e-01],\n",
      "          ...,\n",
      "          [-1.4981e+00, -1.4981e+00, -1.4981e+00,  ..., -1.0334e+00,\n",
      "           -1.0783e+00, -1.0184e+00],\n",
      "          [-1.4981e+00, -1.4981e+00, -1.4981e+00,  ..., -1.0184e+00,\n",
      "           -1.1533e+00, -1.1983e+00],\n",
      "          [-1.4981e+00, -1.4981e+00, -1.4981e+00,  ..., -1.0334e+00,\n",
      "           -1.2582e+00, -1.3931e+00]]]]), tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6, 4, 3, 6, 6,\n",
      "        2, 6, 3, 5, 4, 0, 0, 9, 1, 3, 4, 0, 3, 7, 3, 3, 5, 2, 2, 7, 1, 1, 1, 2,\n",
      "        2, 0, 9, 5, 7, 9, 2, 2, 5, 2, 4, 3, 1, 1, 8, 2])]\n"
     ]
    }
   ],
   "source": [
    "# À quoi ressemblent nos données?\n",
    "for i,data in enumerate(train_loader):\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1288, 0.5807, 0.7934, 0.1474, 0.1539],\n",
      "        [0.7463, 0.6726, 0.8842, 0.6967, 0.4744]])\n"
     ]
    }
   ],
   "source": [
    "# petit rappel de resizing avec pytorch.\n",
    "y = torch.rand([2,5])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1288, 0.5807, 0.7934, 0.1474, 0.1539, 0.7463, 0.6726, 0.8842, 0.6967,\n",
       "         0.4744]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# le 1 veut dire je veux que tu transforme mon tenseur en tenseur de dimension 1\n",
    "# le -1 signifie, quelques soit le nombre de colonne et de raws, fait en sorte que ca fonctionne\n",
    "y.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1187, 0.0795, 0.3406, 0.2688, 0.4434],\n",
      "        [0.2191, 0.1615, 0.3506, 0.7800, 0.0529],\n",
      "        [0.2430, 0.5441, 0.4596, 0.4016, 0.2942],\n",
      "        [0.4185, 0.1697, 0.5202, 0.4033, 0.3203],\n",
      "        [0.0815, 0.7495, 0.0012, 0.1376, 0.8433],\n",
      "        [0.3278, 0.4625, 0.7013, 0.9164, 0.9763],\n",
      "        [0.9629, 0.8470, 0.3611, 0.3025, 0.8163],\n",
      "        [0.6460, 0.5118, 0.8193, 0.2249, 0.8175],\n",
      "        [0.4882, 0.1376, 0.7544, 0.5999, 0.4863],\n",
      "        [0.9527, 0.1000, 0.7469, 0.0999, 0.0518],\n",
      "        [0.8223, 0.7987, 0.0907, 0.4766, 0.1714],\n",
      "        [0.0691, 0.7031, 0.6539, 0.0909, 0.4264],\n",
      "        [0.6502, 0.4836, 0.6966, 0.1184, 0.0336],\n",
      "        [0.2146, 0.5537, 0.3411, 0.8942, 0.0402],\n",
      "        [0.2197, 0.9777, 0.4056, 0.8536, 0.3023],\n",
      "        [0.8829, 0.2198, 0.2317, 0.4551, 0.3274],\n",
      "        [0.5367, 0.6431, 0.0293, 0.0907, 0.2548]])\n"
     ]
    }
   ],
   "source": [
    "#autre exemple\n",
    "x = torch.rand([17,5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1187, 0.0795, 0.3406, 0.2688, 0.4434, 0.2191, 0.1615, 0.3506, 0.7800,\n",
       "         0.0529, 0.2430, 0.5441, 0.4596, 0.4016, 0.2942, 0.4185, 0.1697, 0.5202,\n",
       "         0.4033, 0.3203, 0.0815, 0.7495, 0.0012, 0.1376, 0.8433, 0.3278, 0.4625,\n",
       "         0.7013, 0.9164, 0.9763, 0.9629, 0.8470, 0.3611, 0.3025, 0.8163, 0.6460,\n",
       "         0.5118, 0.8193, 0.2249, 0.8175, 0.4882, 0.1376, 0.7544, 0.5999, 0.4863,\n",
       "         0.9527, 0.1000, 0.7469, 0.0999, 0.0518, 0.8223, 0.7987, 0.0907, 0.4766,\n",
       "         0.1714, 0.0691, 0.7031, 0.6539, 0.0909, 0.4264, 0.6502, 0.4836, 0.6966,\n",
       "         0.1184, 0.0336, 0.2146, 0.5537, 0.3411, 0.8942, 0.0402, 0.2197, 0.9777,\n",
       "         0.4056, 0.8536, 0.3023, 0.8829, 0.2198, 0.2317, 0.4551, 0.3274, 0.5367,\n",
       "         0.6431, 0.0293, 0.0907, 0.2548]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connaitre la taille des inputs de sortie des maxpool par exemple avant la FC\n",
    "# Contrairement aux couches conv dans pyTorch, où l'on a pas besoin de spécifier la taille d'entrée, \n",
    "# on doit le spécifier pour les couches entièrement connectées (FC layers).\n",
    "# Ainsi, lorsque vous définissez la dimension d'entrée de la première couche linéaire, \n",
    "# vous devez savoir quelle est la taille des images que vous alimentez\n",
    "# On créé une classe qui fera cela pour nous\n",
    "\n",
    "class Print(nn.Module):\n",
    "    def forward(self, x):\n",
    "        #print((x.size())\n",
    "        return x.view(x.size(0),-1)\n",
    "a = Print()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*64*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super.__init__()\n",
    "        \n",
    "        self.Linear = nn.Linear(12288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ea541f12be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# On reprend un reseau de neurones simple mais en y ajoutant des convolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# ds cet ordre pr la Conv2D -> channel, filtres (nombre d outputs features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# On reprend un reseau de neurones simple mais en y ajoutant des convolutions\n",
    "class Brain(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # ds cet ordre pr la Conv2D -> channel, filtres (nombre d outputs features) \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        # 6 represente le nbre de feature en output\n",
    "        self.conv2 = nn.Conv2d(32, 6, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(384, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        \n",
    "        # D'où vient ce 8*8*6\n",
    "        # En keras ou tensorflow il exist la methode flatten\n",
    "        # Mais comment faire en pytorch?\n",
    "        # source: http://cs231n.github.io/convolutional-networks/#pool\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=maxpool2#torch.nn.Conv2d\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=maxpool2#torch.nn.MaxPool2d\n",
    "        \n",
    "        out = a.forward(out)\n",
    "        print(out.shape)\n",
    "        print(out.shape[1])\n",
    "        \n",
    "        #out = out.view(-1, 8*8*6)\n",
    "        #a.forward(out)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = Brain()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        \n",
    "        print('{} Epoch {}, Training loss {}'.format(\n",
    "            datetime.datetime.now(), epoch, float(loss_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Brain()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training sur fake dataset\n",
    "#training_loop(n_epochs = 100,optimizer = optimizer,model = model,loss_fn = loss_fn,train_loader = fake_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n",
      "torch.Size([64, 384])\n",
      "384\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-42b9ca1cf45d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-ffff1992e29a>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, loss_fn, train_loader)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/fastai/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs = 100,optimizer = optimizer,model = model,loss_fn = loss_fn,train_loader = train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loader in [train_loader, val_loader]:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "    \n",
    "    print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path + 'CIFAR_10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# faire une prediction sur une image non vue et printer cette prediction\n",
    "model_entraine = Brain()\n",
    "model_entraine.load_state_dict(torch.load(data_path + 'CIFAR_10.pt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le même modèle mais avec un resnet block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition dun block Resnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On reprend un reseau de neurones simple mais en y ajoutant des convolutions\n",
    "class BrainALaResnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # ds cet ordre pr la Conv2D -> channel, filtres (nombre d outputs features) \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = Brain()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rajouter: \n",
    "# regularization\n",
    "# dropout\n",
    "# batch normalization\n",
    "# data augmentation\n",
    "# transfer learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet Block\n",
    "# data_augmentation\n",
    "# object_detection    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
